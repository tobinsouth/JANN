{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Preamble for most code and jupyter notebooks\n",
    "@author: tobinsouth\n",
    "@notebook date: 9 Sep 2021\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np, pandas as pd, matplotlib.pyplot as plt, matplotlib as mpl, seaborn as sns\n",
    "import math, string, re, pickle, json, os, sys, datetime, itertools, glob\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Set panda's options\n",
    "pd.set_option(\"display.max_rows\", 50)\n",
    "pd.set_option(\"display.max_columns\", 120)\n",
    "\n",
    "# Better graphics\n",
    "from matplotlib_inline.backend_inline import set_matplotlib_formats\n",
    "set_matplotlib_formats('retina')\n",
    "plt.style.use('seaborn-poster')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful for code, also may need to navigate there to run following snippets.\n",
    "data_path = '/u/tsouth/projects/educationText/data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we need to convert the file to a wav:\n",
    "\n",
    "`ffmpeg -i SpanishMovie.mp4 -vn -acodec pcm_s16le -ar 44100 -ac 2 fullmovieaudio.wav`\n",
    "\n",
    "and\n",
    "\n",
    "`ffmpeg -ss 3120 -t 60 -i fullmovieaudio.wav clip.wav`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, to run you need to split audio into segments no-longer that 120 seconds. This can be done via:\n",
    "`ffmpeg -i fullmovieaudio.wav -f segment -segment_time 119 -c copy moviesplit/split%03d.wav`\n",
    "\n",
    "Alternatively, you can first split files where their are silences. Note that you will probably still need to split into 120s segments.\n",
    "\n",
    "```bash\n",
    "ffmpeg -i \"fullmovieaudio.wav\" -af silencedetect=noise=-50dB:d=0.5 -f null - 2> vol.txt\n",
    "ffmpeg -ss <silence_end - 0.25> -t <next_silence_start - silence_end + 2 * 0.25> -i input.mov word-N.mov\n",
    "```\n",
    "\n",
    "As a oneliner:\n",
    "\n",
    "```\n",
    "ffmpeg -i fullmovieaudio.wav -filter_complex \"[0:a]silencedetect=n=-40dB:d=0.3[outa]\" -map [outa] -f s16le -y /dev/null |& F='-aq 70 -v warning' perl -ne 'INIT { $ss=0; $se=0; } if (/silence_start: (\\S+)/) { $ss=$1; $ctr+=1; printf \"ffmpeg -nostdin -i fullmovieaudio.wav -ss %f -t %f $ENV{F} -y moviesplit/%03d.wav\\n\", $se, ($ss-$se), $ctr; }  if (/silence_end: (\\S+)/) { $se=$1; } END { printf \"ffmpeg -nostdin -i fullmovieaudio.wav -ss %f $ENV{F} -y moviesplit/%03d.wav\\n\", $se, $ctr+1; }' | bash -x\n",
    "```\n",
    "\n",
    "May want to remove extremely small files:\n",
    "`find moviesplit/. -name \"*.wav\" -type 'f' -size -160k -delete`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from asrecognition import ASREngine\n",
    "# https://huggingface.co/jonatasgrosman/wav2vec2-large-xlsr-53-spanish\n",
    "models = [\"facebook/wav2vec2-large-xlsr-53-spanish\", \"jonatasgrosman/wav2vec2-large-xlsr-53-spanish\",\"flax-community/wav2vec2-spanish\"]# \"facebook/s2t-medium-mustc-multilingual-st\",]\n",
    "for model in tqdm(models):\n",
    "    asr = ASREngine(\"es\", model_path=model)\n",
    "    audio_paths = glob.glob(data_path+\"moviesplit/*.wav\")\n",
    "    transcriptions = asr.transcribe(audio_paths)\n",
    "\n",
    "    tmap = {int(t['path'][-7:-4]): t['transcription'] for t in transcriptions}\n",
    "    full_transcription = ' '.join(tmap[i] for i in range(len(tmap)))\n",
    "    open(models.replacce('/','_')+'.txt').write(full_transcription)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alt approach:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at flax-community/wav2vec2-spanish and are newly initialized: ['lm_head.weight', 'lm_head.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# from asrecognition import ASREngine\n",
    "asr_alt = ASREngine(\"es\", model_path=\"flax-community/wav2vec2-spanish\")\n",
    "# asr_alt = ASREngine(\"es\", model_path=\"facebook/s2t-medium-mustc-multilingual-st\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_paths = glob.glob(data_path+\"moviesplit/*.wav\")\n",
    "transcriptions = asr_alt.transcribe(audio_paths)\n",
    "\n",
    "tmap = {int(t['path'][-7:-4]): t['transcription'] for t in transcriptions}\n",
    "full_transcription = ' '.join(tmap[i] for i in range(len(tmap)))\n",
    "open('tobin_transcribed.txt').write(full_transcription)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(data_path + 'tobin_transcribed.txt', 'r') as f:\n",
    "    fb_trans = f.read()\n",
    "\n",
    "with open(data_path + 'subtitles_final.txt', 'r') as f:\n",
    "    subtitles_final = f.read()\n",
    "\n",
    "with open(data_path + 'script_sp.txt', 'r') as f:\n",
    "    script_sp = f.read()\n",
    "\n",
    "with open(data_path + 'script_mx.txt', 'r') as f:\n",
    "    script_mx = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "Pfb_trans = Counter(fb_trans.split())\n",
    "Psubtitles_final =  Counter(subtitles_final.split())\n",
    "Pscript_sp =  Counter(script_sp.split())\n",
    "Pscript_mx =  Counter(script_mx.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth = list(set(Psubtitles_final.keys()))\n",
    "Pground_truth = [Psubtitles_final[k] for k in ground_truth]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Facebook 0.6370062146900024\n",
      "Spanish 0.6995193559342343\n",
      "Mexican 0.7882892806597096\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mutual_info_score\n",
    "print(\"Facebook\", mutual_info_score(Pground_truth, [Pfb_trans[k] for k in ground_truth]))\n",
    "print(\"Spanish\" , mutual_info_score(Pground_truth, [Pscript_sp[k] for k in ground_truth]))\n",
    "print(\"Mexican\", mutual_info_score(Pground_truth, [Pscript_mx[k] for k in ground_truth]))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c854730bd06fef4a089243d2501fb3b7e98cc6cf4ccc2cce9e8cdf48ee542ef6"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
